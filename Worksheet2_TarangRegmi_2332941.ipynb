{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **Some Helper Function:**"
      ],
      "metadata": {
        "id": "kpi5f-NuuRbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding Data"
      ],
      "metadata": {
        "id": "j5rSSTzk57Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset used:"
      ],
      "metadata": {
        "id": "WUOYNWKy6Jg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o4CrpxoN6PnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification, make_circles\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W0l00UrG6g6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/drive/MyDrive/AI and ML/Week2/Iris.csv.xlsx\") # changed to read_csv and the correct file name\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Information:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "baNnURXM6dlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 1:-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "y_one_hot = one_hot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
        "\n",
        "print(\"\\nUnique Classes:\", np.unique(y))\n",
        "print(\"Encoded Labels:\", np.unique(y_encoded))\n",
        "print(\"One-Hot Encoded Labels:\\n\", y_one_hot[:5])"
      ],
      "metadata": {
        "id": "NiZ-vwkp67-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot)\n",
        "\n",
        "print(\"\\nShapes:\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)"
      ],
      "metadata": {
        "id": "2NZh0cQT7CML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Function:"
      ],
      "metadata": {
        "id": "NDqrxMpLuhLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    \"\"\"\n",
        "    Compute the softmax probabilities for a given input matrix.\n",
        "\n",
        "    Parameters:\n",
        "    z (numpy.ndarray): Logits (raw scores) of shape (m, n), where\n",
        "                       - m is the number of samples.\n",
        "                       - n is the number of classes.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Softmax probability matrix of shape (m, n), where\n",
        "                   each row sums to 1 and represents the probability\n",
        "                   distribution over classes.\n",
        "\n",
        "    Notes:\n",
        "    - The input to softmax is typically computed as: z = XW + b.\n",
        "    - Uses numerical stabilization by subtracting the max value per row.\n",
        "    \"\"\"\n",
        "    z_shifted = z - np.max(z, axis=1, keepdims=True)\n",
        "    exp_z = np.exp(z_shifted)\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "YoOjTJJpt6Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax Test Case:\n",
        "\n",
        "This test case checks that each row in the resulting softmax probabilities sums to 1, which is the fundamental property of softmax."
      ],
      "metadata": {
        "id": "ZFnMdHJzrUJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_test = np.array([[2.0, 1.0, 0.1], [1.0, 1.0, 1.0]])\n",
        "softmax_output = softmax(z_test)\n",
        "\n",
        "row_sums = np.sum(softmax_output, axis=1)\n",
        "\n",
        "assert np.allclose(row_sums, 1), f\"Test failed: Row sums are {row_sums}\"\n",
        "\n",
        "print(\"Softmax function passed the test case!\")"
      ],
      "metadata": {
        "id": "qL5ToHmkrTr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Function:"
      ],
      "metadata": {
        "id": "j1uPYyhotoAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_softmax(X, W, b):\n",
        "    \"\"\"\n",
        "    Predict the class labels for a set of samples using the trained softmax model.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c), where c is the number of classes.\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: Predicted class labels of shape (n,), where each value is the index of the predicted class.\n",
        "    \"\"\"\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "\n",
        "    predicted_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    return predicted_classes"
      ],
      "metadata": {
        "id": "8qwCbgC1vyHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Function for Prediction Function:\n",
        "The test function ensures that the predicted class labels have the same number of elements as the input samples, verifying that the model produces a valid output shape."
      ],
      "metadata": {
        "id": "LCGDTavVuXZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([[0.2, 0.8], [0.5, 0.5], [0.9, 0.1]])\n",
        "W_test = np.array([[0.4, 0.2, 0.1], [0.3, 0.7, 0.5]])\n",
        "b_test = np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "y_pred_test = predict_softmax(X_test, W_test, b_test)\n",
        "\n",
        "assert y_pred_test.shape == (3,), f\"Test failed: Expected shape (3,), got {y_pred_test.shape}\"\n",
        "\n",
        "print(\"Predicted class labels:\", y_pred_test)"
      ],
      "metadata": {
        "id": "musr99YhucQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function:"
      ],
      "metadata": {
        "id": "JwejxbajvEle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_softmax(y_pred, y):\n",
        "    \"\"\"\n",
        "    Compute the cross-entropy loss for a single sample.\n",
        "\n",
        "    Parameters:\n",
        "    y_pred (numpy.ndarray): Predicted probabilities of shape (c,) for a single sample,\n",
        "                             where c is the number of classes.\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (c,), where c is the number of classes.\n",
        "\n",
        "    Returns:\n",
        "    float: Cross-entropy loss for the given sample.\n",
        "    \"\"\"\n",
        "\n",
        "    epsilon = 1e-12\n",
        "    y_pred = np.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "    n = y.shape[0]\n",
        "    loss = -np.sum(y * np.log(y_pred)) / n\n",
        "    return loss"
      ],
      "metadata": {
        "id": "bjqnULCtun_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test case for Loss Function:\n",
        "This test case Compares loss for correct vs. incorrect predictions.\n",
        "*   Expects low loss for correct predictions.\n",
        "*   Expects high loss for incorrect predictions."
      ],
      "metadata": {
        "id": "fXdMIV_cz5Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_true_correct = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "y_pred_correct = np.array([[0.9, 0.05, 0.05],\n",
        "                           [0.1, 0.85, 0.05],\n",
        "                           [0.05, 0.1, 0.85]])\n",
        "\n",
        "y_pred_incorrect = np.array([[0.05, 0.05, 0.9],\n",
        "                              [0.1, 0.05, 0.85],\n",
        "                              [0.85, 0.1, 0.05]])\n",
        "\n",
        "loss_correct = loss_softmax(y_pred_correct, y_true_correct)\n",
        "loss_incorrect = loss_softmax(y_pred_incorrect, y_true_correct)\n",
        "\n",
        "assert loss_correct < loss_incorrect, f\"Test failed: Expected loss_correct < loss_incorrect, but got {loss_correct:.4f} >= {loss_incorrect:.4f}\"\n",
        "\n",
        "print(f\"Cross-Entropy Loss (Correct Predictions): {loss_correct:.4f}\")\n",
        "print(f\"Cross-Entropy Loss (Incorrect Predictions): {loss_incorrect:.4f}\")"
      ],
      "metadata": {
        "id": "2IhRGquu0N9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost Function:"
      ],
      "metadata": {
        "id": "y0d3fm1-vUlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the average softmax regression cost (cross-entropy loss) over all samples.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d), where n is the number of samples and d is the number of features.\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c), where n is the number of samples and c is the number of classes.\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    float: Average softmax cost (cross-entropy loss) over all samples.\n",
        "    \"\"\"\n",
        "\n",
        "    n = X.shape[0]\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "    cost = loss_softmax(y_pred, y)\n",
        "    return cost"
      ],
      "metadata": {
        "id": "yaH9_s0svIGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Case for Cost Function:\n",
        "The test case assures that the cost for the incorrect prediction should be higher than for the correct prediction, confirming that the cost function behaves as expected."
      ],
      "metadata": {
        "id": "-eGyPFJ33tgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_correct = np.array([[1.0, 0.0], [0.0, 1.0]])\n",
        "y_correct = np.array([[1, 0], [0, 1]])\n",
        "W_correct = np.array([[5.0, -2.0], [-3.0, 5.0]])\n",
        "b_correct = np.array([0.1, 0.1])\n",
        "\n",
        "X_incorrect = np.array([[0.1, 0.9], [0.8, 0.2]])\n",
        "y_incorrect = np.array([[1, 0], [0, 1]])\n",
        "W_incorrect = np.array([[0.1, 2.0], [1.5, 0.3]])\n",
        "b_incorrect = np.array([0.5, 0.6])\n",
        "\n",
        "cost_correct = cost_softmax(X_correct, y_correct, W_correct, b_correct)\n",
        "\n",
        "cost_incorrect = cost_softmax(X_incorrect, y_incorrect, W_incorrect, b_incorrect)\n",
        "\n",
        "assert cost_incorrect > cost_correct, f\"Test failed: Incorrect cost {cost_incorrect} is not greater than correct cost {cost_correct}\"\n",
        "\n",
        "print(\"Cost for correct prediction:\", cost_correct)\n",
        "print(\"Cost for incorrect prediction:\", cost_incorrect)\n",
        "\n",
        "print(\"Test passed!\")\n"
      ],
      "metadata": {
        "id": "MIGAxYQt36Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing Gradients:"
      ],
      "metadata": {
        "id": "v-YIb7zlveKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_softmax(X, y, W, b):\n",
        "    \"\"\"\n",
        "    Compute the gradients of the cost function with respect to weights and biases.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Gradients with respect to weights (d, c) and biases (c,).\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    n, d = X.shape\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = softmax(z)\n",
        "\n",
        "    grad_W = np.dot(X.T, (y_pred - y)) / n\n",
        "    grad_b = np.sum(y_pred - y, axis=0) / n\n",
        "\n",
        "    return grad_W, grad_b"
      ],
      "metadata": {
        "id": "G3Vpn5bNvW3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test case for compute_gradient function:\n",
        "The test checks if the gradients from the function are close enough to the manually computed gradients using np.allclose, which accounts for potential floating-point discrepancies."
      ],
      "metadata": {
        "id": "S84yoIUx7vY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_test = np.array([[0.2, 0.8], [0.5, 0.5], [0.9, 0.1]])\n",
        "y_test = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "\n",
        "W_test = np.array([[0.4, 0.2, 0.1], [0.3, 0.7, 0.5]])\n",
        "b_test = np.array([0.1, 0.2, 0.3])\n",
        "\n",
        "grad_W, grad_b = compute_gradient_softmax(X_test, y_test, W_test, b_test)\n",
        "\n",
        "z_test = np.dot(X_test, W_test) + b_test\n",
        "y_pred_test = softmax(z_test)\n",
        "\n",
        "grad_W_manual = np.dot(X_test.T, (y_pred_test - y_test)) / X_test.shape[0]\n",
        "grad_b_manual = np.sum(y_pred_test - y_test, axis=0) / X_test.shape[0]\n",
        "\n",
        "assert np.allclose(grad_W, grad_W_manual), f\"Test failed: Gradients w.r.t. W are not equal.\\nExpected: {grad_W_manual}\\nGot: {grad_W}\"\n",
        "assert np.allclose(grad_b, grad_b_manual), f\"Test failed: Gradients w.r.t. b are not equal.\\nExpected: {grad_b_manual}\\nGot: {grad_b}\"\n",
        "\n",
        "print(\"Gradient w.r.t. W:\", grad_W)\n",
        "print(\"Gradient w.r.t. b:\", grad_b)\n",
        "\n",
        "print(\"Test passed!\")\n"
      ],
      "metadata": {
        "id": "l-YSC_Ot70bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Gradient Descent:"
      ],
      "metadata": {
        "id": "W75VL71ivpjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_softmax(X, y, W, b, alpha, n_iter, show_cost=False):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize the weights and biases.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix of shape (n, d).\n",
        "    y (numpy.ndarray): True labels (one-hot encoded) of shape (n, c).\n",
        "    W (numpy.ndarray): Weight matrix of shape (d, c).\n",
        "    b (numpy.ndarray): Bias vector of shape (c,).\n",
        "    alpha (float): Learning rate.\n",
        "    n_iter (int): Number of iterations.\n",
        "    show_cost (bool): Whether to display the cost at intervals.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Optimized weights, biases, and cost history.\n",
        "    \"\"\"\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        grad_W, grad_b = compute_gradient_softmax(X, y, W, b)\n",
        "\n",
        "        W -= alpha * grad_W\n",
        "        b -= alpha * grad_b\n",
        "\n",
        "        cost = cost_softmax(X, y, W, b)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        if show_cost and (i % 100 == 0 or i == n_iter - 1):\n",
        "            print(f\"Iteration {i}: Cost = {cost:.6f}\")\n",
        "\n",
        "    return W, b, cost_history\n"
      ],
      "metadata": {
        "id": "bbQ7SVw7vo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Dataset:"
      ],
      "metadata": {
        "id": "zBG9uSWKHDgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_prepare_mnist(csv_file, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Reads the MNIST CSV file, splits data into train/test sets, and plots one image per class.\n",
        "\n",
        "    Arguments:\n",
        "    csv_file (str)       : Path to the CSV file containing MNIST data.\n",
        "    test_size (float)    : Proportion of the data to use as the test set (default: 0.2).\n",
        "    random_state (int)   : Random seed for reproducibility (default: 42).\n",
        "\n",
        "    Returns:\n",
        "    X_train, X_test, y_train, y_test : Split dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    y = df.iloc[:, 0].values\n",
        "    X = df.iloc[:, 1:].values\n",
        "\n",
        "    X = X / 255.0\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    plot_sample_images(X, y)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def plot_sample_images(X, y):\n",
        "    \"\"\"\n",
        "    Plots one sample image for each digit class (0-9).\n",
        "\n",
        "    Arguments:\n",
        "    X (np.ndarray): Feature matrix containing pixel values.\n",
        "    y (np.ndarray): Labels corresponding to images.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    unique_classes = np.unique(y)\n",
        "\n",
        "    for i, digit in enumerate(unique_classes):\n",
        "        index = np.where(y == digit)[0][0]\n",
        "        image = X[index].reshape(28, 28)\n",
        "\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f\"Digit: {digit}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "prZ_zAvLpodE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/drive/MyDrive/AI and ML/Week2/mnist_dataset.csv\"\n",
        "X_train, X_test, y_train, y_test = load_and_prepare_mnist(csv_file_path)"
      ],
      "metadata": {
        "id": "ZtYR42Qas2uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A Quick debugging Step:**"
      ],
      "metadata": {
        "id": "MyMBH4mQtzHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(X_train) == len(y_train), f\"Error: X and y have different lengths! X={len(X_train)}, y={len(y_train)}\"\n",
        "print(\"Move forward: Dimension of Feture Matrix X and label vector y matched.\")"
      ],
      "metadata": {
        "id": "QIJhtnuCs7QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train the Model:**"
      ],
      "metadata": {
        "id": "-TKIsKJcwFsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "fEuTbCU0xAQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "if len(y_train.shape) == 1:\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "    y_test = encoder.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "d = X_train.shape[1]\n",
        "c = y_train.shape[1]\n",
        "\n",
        "W = np.random.randn(d, c) * 0.01\n",
        "b = np.zeros(c)\n",
        "\n",
        "alpha = 0.1\n",
        "n_iter = 1000\n",
        "\n",
        "W_opt, b_opt, cost_history = gradient_descent_softmax(X_train, y_train, W, b, alpha, n_iter, show_cost=True)\n",
        "\n",
        "plt.plot(cost_history)\n",
        "plt.title('Cost Function vs. Iterations')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8e2mHmRv4fd",
        "outputId": "26621cdf-93fa-4a41-fe9e-349622481bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0: Cost = 0.000000\n",
            "Iteration 100: Cost = 0.000000\n",
            "Iteration 200: Cost = 0.000000\n",
            "Iteration 300: Cost = 0.000000\n",
            "Iteration 400: Cost = 0.000000\n",
            "Iteration 500: Cost = 0.000000\n",
            "Iteration 600: Cost = 0.000000\n",
            "Iteration 700: Cost = 0.000000\n",
            "Iteration 800: Cost = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating the Model:**"
      ],
      "metadata": {
        "id": "tH4wNbhzys4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluate classification performance using confusion matrix, precision, recall, and F1-score.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (numpy.ndarray): True labels\n",
        "    y_pred (numpy.ndarray): Predicted labels\n",
        "\n",
        "    Returns:\n",
        "    tuple: Confusion matrix, precision, recall, F1 score\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    return cm, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "lzV7BkRqOl5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = predict_softmax(X_test, W_opt, b_opt)\n",
        "\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm, precision, recall, f1 = evaluate_classification(y_test_labels, y_pred_test)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "cax = ax.imshow(cm, cmap='Blues')\n",
        "\n",
        "num_classes = cm.shape[0]\n",
        "ax.set_xticks(range(num_classes))\n",
        "ax.set_yticks(range(num_classes))\n",
        "ax.set_xticklabels([f'Predicted {i}' for i in range(num_classes)])\n",
        "ax.set_yticklabels([f'Actual {i}' for i in range(num_classes)])\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white' if cm[i, j] > np.max(cm) / 2 else 'black')\n",
        "\n",
        "ax.grid(False)\n",
        "plt.title('Confusion Matrix', fontsize=14)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('Actual Label', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.colorbar(cax)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uuGtvIlywK7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Seperability and Logistic Regression:"
      ],
      "metadata": {
        "id": "yv8J5hNCPzl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_circles(n_samples=1000, factor=0.5, noise=0.1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 100),\n",
        "                     np.linspace(X[:, 1].min(), X[:, 1].max(), 100))\n",
        "\n",
        "Z = log_reg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.contourf(xx, yy, Z, levels=[0, 0.5], cmap='Blues', alpha=0.2)\n",
        "\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', edgecolors='k', marker='o', label='Train')\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', edgecolors='k', marker='x', label='Test')\n",
        "\n",
        "plt.title(\"Logistic Regression on Non-linear Data (Circles)\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CTyaPcM-P69S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "X_linear_separable, y_linear_separable = make_classification(n_samples=200, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
        "X_train_linear, X_test_linear, y_train_linear, y_test_linear = train_test_split(X_linear_separable, y_linear_separable, test_size=0.2, random_state=42)\n",
        "logistic_model_linear_separable = LogisticRegression()\n",
        "logistic_model_linear_separable.fit(X_train_linear, y_train_linear)\n",
        "\n",
        "X_non_linear_separable, y_non_linear_separable = make_circles(n_samples=200, noise=0.1, factor=0.5, random_state=42)\n",
        "X_train_non_linear, X_test_non_linear, y_train_non_linear, y_test_non_linear = train_test_split(X_non_linear_separable, y_non_linear_separable, test_size=0.2, random_state=42)\n",
        "logistic_model_non_linear_separable = LogisticRegression()\n",
        "logistic_model_non_linear_separable.fit(X_train_non_linear, y_train_non_linear)\n",
        "\n",
        "def plot_decision_boundary(ax, model, X, y, title):\n",
        "    h = 0.02\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.Paired)\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Feature 1\")\n",
        "    ax.set_ylabel(\"Feature 2\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "plot_decision_boundary(axes[0, 0], logistic_model_linear_separable, X_train_linear, y_train_linear, \"Linearly Separable Data (Training)\")\n",
        "plot_decision_boundary(axes[0, 1], logistic_model_linear_separable, X_test_linear, y_test_linear, \"Linearly Separable Data (Testing)\")\n",
        "plot_decision_boundary(axes[1, 0], logistic_model_non_linear_separable, X_train_non_linear, y_train_non_linear, \"Non-Linearly Separable Data (Training)\")\n",
        "plot_decision_boundary(axes[1, 1], logistic_model_non_linear_separable, X_test_non_linear, y_test_non_linear, \"Non-Linearly Separable Data (Testing)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EmxJFCCOiEXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Questions:"
      ],
      "metadata": {
        "id": "XDbjLkyrlyHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Provide an interpretation of the output based on your understanding.\n",
        "- In the linearly separable data we can see that the decision boundary is able to properly seperate the two classes. From the diagrams we can see that most of the classes are classified or predicted correctly in both training and testing which tells us that logistic regression works well on linear data.\n",
        "- But in the non-linearly separable data we can see that the decision boundary is unable to seperate the two classes properl as the decision boundary is still linear but the data points are circular. Most of the points are incorrectly classified which shows that logistic regression is not suitable for non linear classificaiton."
      ],
      "metadata": {
        "id": "rk18lAqekk7K"
      }
    }
  ]
}